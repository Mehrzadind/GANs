{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchsummary import summary\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True     \n",
    "DATA_PATH = './Data/mnist'\n",
    "OUT_PATH = 'output'\n",
    "LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "BATCH_SIZE = 128       \n",
    "IMAGE_CHANNEL = 1\n",
    "# IMAGE_CHANNEL = 3\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 25\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "lr = 2e-4\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to output\\log.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.clear_folder(OUT_PATH)\n",
    "print(\"Logging to {}\\n\".format(LOG_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.6.0\n",
      "CUDA version: 10.2\n",
      "\n",
      "Random Seed:  1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1           [128, 512, 4, 4]         819,200\n",
      "       BatchNorm2d-2           [128, 512, 4, 4]           1,024\n",
      "              ReLU-3           [128, 512, 4, 4]               0\n",
      "   ConvTranspose2d-4           [128, 256, 8, 8]       2,097,152\n",
      "       BatchNorm2d-5           [128, 256, 8, 8]             512\n",
      "              ReLU-6           [128, 256, 8, 8]               0\n",
      "   ConvTranspose2d-7         [128, 128, 16, 16]         524,288\n",
      "       BatchNorm2d-8         [128, 128, 16, 16]             256\n",
      "              ReLU-9         [128, 128, 16, 16]               0\n",
      "  ConvTranspose2d-10          [128, 64, 32, 32]         131,072\n",
      "      BatchNorm2d-11          [128, 64, 32, 32]             128\n",
      "             ReLU-12          [128, 64, 32, 32]               0\n",
      "  ConvTranspose2d-13           [128, 1, 64, 64]           1,024\n",
      "             Tanh-14           [128, 1, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 3,574,656\n",
      "Trainable params: 3,574,656\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 368.00\n",
      "Params size (MB): 13.64\n",
      "Estimated Total Size (MB): 381.69\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [128, 64, 32, 32]           1,024\n",
      "         LeakyReLU-2          [128, 64, 32, 32]               0\n",
      "            Conv2d-3         [128, 128, 16, 16]         131,072\n",
      "       BatchNorm2d-4         [128, 128, 16, 16]             256\n",
      "         LeakyReLU-5         [128, 128, 16, 16]               0\n",
      "            Conv2d-6           [128, 256, 8, 8]         524,288\n",
      "       BatchNorm2d-7           [128, 256, 8, 8]             512\n",
      "         LeakyReLU-8           [128, 256, 8, 8]               0\n",
      "            Conv2d-9           [128, 512, 4, 4]       2,097,152\n",
      "      BatchNorm2d-10           [128, 512, 4, 4]           1,024\n",
      "        LeakyReLU-11           [128, 512, 4, 4]               0\n",
      "           Conv2d-12             [128, 1, 1, 1]           8,192\n",
      "          Sigmoid-13             [128, 1, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 2,763,520\n",
      "Trainable params: 2,763,520\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.00\n",
      "Forward/backward pass size (MB): 296.00\n",
      "Params size (MB): 10.54\n",
      "Estimated Total Size (MB): 308.54\n",
      "----------------------------------------------------------------\n",
      "Epoch 0 [0/469] loss_D_real: 0.6289 loss_D_fake: 0.7797 loss_G: 4.3319\n",
      "Epoch 0 [100/469] loss_D_real: 0.0722 loss_D_fake: 0.0528 loss_G: 4.5001\n",
      "Epoch 0 [200/469] loss_D_real: 1.6751 loss_D_fake: 0.0349 loss_G: 2.1043\n",
      "Epoch 0 [300/469] loss_D_real: 0.2022 loss_D_fake: 0.1001 loss_G: 2.5148\n",
      "Epoch 0 [400/469] loss_D_real: 0.0000 loss_D_fake: 7.0598 loss_G: 3.9486\n",
      "Epoch 1 [0/469] loss_D_real: 0.0348 loss_D_fake: 0.2893 loss_G: 3.5798\n",
      "Epoch 1 [100/469] loss_D_real: 0.0817 loss_D_fake: 0.4902 loss_G: 3.2732\n",
      "Epoch 1 [200/469] loss_D_real: 2.5138 loss_D_fake: 0.0171 loss_G: 1.9898\n",
      "Epoch 1 [300/469] loss_D_real: 0.8086 loss_D_fake: 0.0319 loss_G: 1.3299\n",
      "Epoch 1 [400/469] loss_D_real: 0.2041 loss_D_fake: 0.1351 loss_G: 2.2082\n",
      "Epoch 2 [0/469] loss_D_real: 0.2004 loss_D_fake: 0.0867 loss_G: 2.4492\n",
      "Epoch 2 [100/469] loss_D_real: 0.0914 loss_D_fake: 0.1684 loss_G: 3.1853\n",
      "Epoch 2 [200/469] loss_D_real: 0.2035 loss_D_fake: 0.0376 loss_G: 1.8083\n",
      "Epoch 2 [300/469] loss_D_real: 0.6056 loss_D_fake: 0.0406 loss_G: 1.2530\n",
      "Epoch 2 [400/469] loss_D_real: 0.0497 loss_D_fake: 0.0967 loss_G: 3.2872\n",
      "Epoch 3 [0/469] loss_D_real: 0.1611 loss_D_fake: 0.1005 loss_G: 2.6818\n",
      "Epoch 3 [100/469] loss_D_real: 0.2205 loss_D_fake: 0.1112 loss_G: 1.9643\n",
      "Epoch 3 [200/469] loss_D_real: 0.1064 loss_D_fake: 0.0936 loss_G: 3.3639\n",
      "Epoch 3 [300/469] loss_D_real: 0.0624 loss_D_fake: 1.1104 loss_G: 4.4715\n",
      "Epoch 3 [400/469] loss_D_real: 0.0207 loss_D_fake: 0.0459 loss_G: 4.3982\n",
      "Epoch 4 [0/469] loss_D_real: 0.0974 loss_D_fake: 0.2202 loss_G: 3.6905\n",
      "Epoch 4 [100/469] loss_D_real: 0.0270 loss_D_fake: 0.0645 loss_G: 4.4311\n",
      "Epoch 4 [200/469] loss_D_real: 3.2059 loss_D_fake: 0.0029 loss_G: 0.1937\n"
     ]
    }
   ],
   "source": [
    "sys.stdout = utils.StdOut(LOG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "\n",
    "if seed is None:\n",
    "    seed = np.random.randint(1, 10000)\n",
    "print(\"Random Seed: \", seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset.MNIST.resources = [\n",
    "#    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
    "#    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
    "#    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
    "#    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=DATA_PATH, \n",
    "                     download=False,\n",
    "                     transform=transforms.Compose([\n",
    "                     transforms.Resize(X_DIM),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5,), (0.5,))\n",
    "                     ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"custom weights initialization\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.ConvTranspose2d(Z_DIM, G_HIDDEN * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 8),\n",
    "            nn.ReLU(True),\n",
    "            # 2nd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 8, G_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 3rd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 4, G_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 2),\n",
    "            nn.ReLU(True),\n",
    "            # 4th layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 2, G_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN),\n",
    "            nn.ReLU(True),\n",
    "            # output layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "#print(netG)\n",
    "summary(netG,input_size=(100,1,1),batch_size=BATCH_SIZE,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Conv2d(\n",
    "#    in_channels: int,\n",
    "#    out_channels: int,\n",
    "#    kernel_size: Union[int, Tuple[int, int]],\n",
    "#    stride: Union[int, Tuple[int, int]] = 1,\n",
    "#    padding: Union[int, Tuple[int, int]] = 0,\n",
    "#    dilation: Union[int, Tuple[int, int]] = 1,\n",
    "#    groups: int = 1,\n",
    "#    bias: bool = True,\n",
    "#    padding_mode: str = 'zeros',\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Conv2d(IMAGE_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 2nd layer\n",
    "            nn.Conv2d(D_HIDDEN, D_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 3rd layer\n",
    "            nn.Conv2d(D_HIDDEN * 2, D_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 4th layer\n",
    "            nn.Conv2d(D_HIDDEN * 4, D_HIDDEN * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # output layer\n",
    "            nn.Conv2d(D_HIDDEN * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "#print(netD)\n",
    "summary(netD,input_size=(1,64,64),batch_size=BATCH_SIZE,device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH_NUM):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        x_real = data[0].to(device)\n",
    "        real_label = torch.full((x_real.size(0),), REAL_LABEL,dtype=torch.float,device=device)\n",
    "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL,dtype=torch.float, device=device)\n",
    "\n",
    "        # Update D with real data\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(x_real)\n",
    "        loss_D_real = criterion(y_real, real_label)\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        # Update D with fake data\n",
    "        z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake = netD(x_fake.detach())\n",
    "        loss_D_fake = criterion(y_fake, fake_label)\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update G with fake data\n",
    "        netG.zero_grad()\n",
    "        y_fake_r = netD(x_fake)\n",
    "        loss_G = criterion(y_fake_r, real_label)\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(\n",
    "                epoch, i, len(dataloader),\n",
    "                loss_D_real.mean().item(),\n",
    "                loss_D_fake.mean().item(),\n",
    "                loss_G.mean().item()\n",
    "            ))\n",
    "            vutils.save_image(x_real, os.path.join(OUT_PATH, 'real_samples.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise)\n",
    "                vutils.save_image(viz_sample, os.path.join(OUT_PATH, 'fake_samples_{}.png'.format(epoch)), normalize=True)\n",
    "    torch.save(netG.state_dict(), os.path.join(OUT_PATH, 'netG_{}.pth'.format(epoch)))\n",
    "    torch.save(netD.state_dict(), os.path.join(OUT_PATH, 'netD_{}.pth'.format(epoch)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
